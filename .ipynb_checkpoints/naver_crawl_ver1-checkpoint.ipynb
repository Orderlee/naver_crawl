{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0439430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from sklearn.cluster import KMeans\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os, glob\n",
    "import os.path\n",
    "import natsort\n",
    "import requests\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015280e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette_perc(k_cluster):\n",
    "    width = 300\n",
    "    palette = np.zeros((50, width, 3), np.uint8)\n",
    "    n_pixels = len(k_cluster.labels_)\n",
    "    counter = Counter(k_cluster.labels_)\n",
    "    perc = {}\n",
    "    for i in counter:\n",
    "        perc[i] = np.round(counter[i]/n_pixels, 2)\n",
    "    perc = dict(sorted(perc.items()))\n",
    "    step = 0\n",
    "    for idx, centers in enumerate(k_cluster.cluster_centers_):\n",
    "        palette[:, step:int(step + perc[idx]*width+1), :] = centers\n",
    "        step += int(perc[idx]*width+1)\n",
    "    return palette, perc, k_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03b0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'}\n",
    "\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\")\n",
    "\n",
    "browser = webdriver.Chrome('./chromedriver',options = options)\n",
    "url='https://shopping.naver.com/home/p/index.naver' #https://m.shopping.naver.com/menu?vertical=HOME #https://shopping.naver.com/home/p/index.naver\n",
    "browser.get(url)\n",
    "\n",
    "search = browser.find_element_by_css_selector('input._searchInput_search_input_QXUFf')\n",
    "# browser.implicitly_wait(10)\n",
    "search.click()\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78db0f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무엇을 검색할까요?:터틀넥\n",
      "Data found3!\n",
      "page =  0 크롤링 완료\n",
      "page =  1 크롤링 완료\n",
      "page =  2 크롤링 완료\n",
      "page =  3 크롤링 완료\n",
      "page =  4 크롤링 완료\n",
      "page =  5 크롤링 완료\n",
      "page =  6 크롤링 완료\n",
      "page =  7 크롤링 완료\n",
      "page =  8 크롤링 완료\n",
      "page =  9 크롤링 완료\n",
      "page =  10 크롤링 완료\n",
      "product: 506\n",
      "categoryL 506\n",
      "item: 506\n",
      "rgb: 2760\n",
      "links 506\n",
      "image_url 368\n",
      "imagefile 368\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "plusUrl = input('무엇을 검색할까요?:')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search.send_keys(plusUrl)\n",
    "# s_prod = search.send_keys('원피스')\n",
    "# s_prod\n",
    "search.send_keys(Keys.ENTER)\n",
    "\n",
    "#검색어 입력시 카테고리 나눔\n",
    "# if plusUrl =='원피스'or '가운드레스' or'니트원피스'or'데님원피스'or\\\n",
    "#         '드레스'or'멜빵원피스'or'셔츠원피스'or'슬립드레스'or'오프숄더드레스'or'웨딩드레스'\\\n",
    "#         or'튜닉원피스'or'튤드레스'or'파자마드레스'or'페플럼드레스'or'피케원피스'or'혹터넥드레스':\n",
    "#     j = '드레스'\n",
    "# if plusUrl =='베스트' or '정장조끼' or '집업베스트' or '패딩조끼':\n",
    "#     j = '베스트'\n",
    "# if plusUrl =='가디건' or '니트베스트' or '스웨터' or '터틀넥':\n",
    "#     j = '니트웨어'\n",
    "# if plusUrl =='블라우스':\n",
    "#     j = '블라우스'\n",
    "# if plusUrl =='셔츠' or '와이셔츠':\n",
    "#     j = '셔츠'\n",
    "# if plusUrl =='스커트' or '데님스커트' or '러플스커트' or '사롱스커트' or '킬트스커트' or\\\n",
    "#     '률스커트' or '트럼펫스커트' or '티어드스커트' or '페플럼스커트' or '플레어스커트' or '플리츠스커트':\n",
    "#     j = '스커트'\n",
    "\n",
    "\n",
    "list1 = ['원피스','가운드레스' ,'니트원피스','데님원피스',\\\n",
    "        '드레스','멜빵원피스','셔츠원피스','슬립드레스','오프숄더드레스','웨딩드레스',\\\n",
    "        '튜닉원피스','튤드레스','파자마드레스','페플럼드레스','피케원피스','혹터넥드레스']\n",
    "\n",
    "list2 = ['베스트','정장조끼' ,'집업베스트' , '패딩조끼']\n",
    "\n",
    "list3 = ['가디건' ,'니트베스트' ,'스웨터' ,'터틀넥']\n",
    "\n",
    "list4 = ['블라우스']\n",
    "\n",
    "list5 = ['셔츠' , '와이셔츠']\n",
    "\n",
    "list6 = ['스커트' , '데님스커트' , '러플스커트' , '사롱스커트' , '킬트스커트' ,\\\n",
    "    '률스커트' , '트럼펫스커트' , '티어드스커트' , '페플럼스커트' , '플레어스커트' , '플리츠스커트']\n",
    "\n",
    "list7 = ['청바지','청반바지']\n",
    "\n",
    "list8 = ['스웨트셔츠','티셔츠','폴로셔츠','후드']\n",
    "\n",
    "list9 = ['가죽코트','더블브레스티드코트','더플코트','랩코트','모피코트','무스탕','밀리터리코트','싱글브레스티드코트','케이프','코트','트렌치코트']\n",
    "\n",
    "list10 = ['뷔스티에','브라탑','캐미솔','탱크탑','튜브탑','파자마상의']\n",
    "\n",
    "list11 = ['패딩']\n",
    "\n",
    "list12 = ['레깅스','배기팬츠','스웨트팬츠','스키팬츠','슬랙스','와이드팬츠','잠옷바지','조거팬츠','치노팬츠','카고팬츠','트랙팬츠','하렘팬츠']\n",
    "\n",
    "list13 = ['재킷','가죽재킷','더블브레스티드재킷','데님재킷','로브','밀리터리재킷','바람막이','바이커재킷','발마칸재킷','볼레로','싱글브레스티드재킷','집업재킷','테일러드재킷','트럭커','피트니스재킷']\n",
    "\n",
    "list14 = ['블루종','야상','집업점퍼','항공점퍼']\n",
    "\n",
    "if plusUrl in list1:\n",
    "    print(\"Data found!\")\n",
    "    j = '드레스'\n",
    "    \n",
    "elif plusUrl in list2:\n",
    "    print('Data found2!')\n",
    "    j='베스트'\n",
    "    \n",
    "elif plusUrl in list3:\n",
    "    print('Data found3!')\n",
    "    j= '니트웨어'\n",
    "elif plusUrl in list4:\n",
    "    print('Data found4!')\n",
    "    j='블라우스'\n",
    "    \n",
    "elif plusUrl in list5:\n",
    "    print('Data found5!')\n",
    "    j ='셔츠'\n",
    "    \n",
    "elif plusUrl in list6:\n",
    "    print('Data Found6!')\n",
    "    j='스커트'\n",
    "\n",
    "elif plusUrl in list7:\n",
    "    print('Data Found7!')\n",
    "    j = '청바지'\n",
    "    \n",
    "elif plusUrl in list8:\n",
    "    print('Data Found8!')\n",
    "    j='캐주얼상의'\n",
    "\n",
    "elif plusUrl in list9:\n",
    "    print('Data Found9!')\n",
    "    j='코트'\n",
    "\n",
    "elif plusUrl in list10:\n",
    "    print('Data Found10!')\n",
    "    j='탑'\n",
    "    \n",
    "elif plusUrl in list11:\n",
    "    print('Data Found11!')\n",
    "    j='패딩'\n",
    "\n",
    "elif plusUrl in list12:\n",
    "    print('Data Found12!')\n",
    "    j='팬츠'\n",
    "    \n",
    "elif plusUrl in list13:\n",
    "    print('Data Found13!')\n",
    "    j='재킷'\n",
    "\n",
    "elif plusUrl in list14:\n",
    "    print('Data Found14!')\n",
    "    j='점퍼'\n",
    "products= []\n",
    "category= []\n",
    "items= []\n",
    "length = []\n",
    "sleeve_length = []\n",
    "color = []\n",
    "rgb=[]\n",
    "# price=[]\n",
    "links = []\n",
    "image_url=[]\n",
    "\n",
    "page=0\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    time.sleep(random.uniform(1,3))\n",
    "\n",
    "    before_h = browser.execute_script('return window.scrollY')\n",
    "\n",
    "    # 무한 스크롤\n",
    "    while True:\n",
    "\n",
    "        # 맨 아래로 스크롤 내림\n",
    "        browser.find_element_by_css_selector(\"body\").send_keys(Keys.PAGE_DOWN) #PAGE_DOWN #END\n",
    "\n",
    "        # 스크롤 사이 페이지 로딩 시간\n",
    "        time.sleep(random.uniform(1,3))\n",
    "\n",
    "        # 스크롤 후 높이\n",
    "\n",
    "        after_h = browser.execute_script(\"return window.scrollY\")\n",
    "\n",
    "        if after_h == before_h:\n",
    "            break\n",
    "        before_h = after_h\n",
    "       \n",
    "    print(\"page = \", page, \"크롤링 완료\")\n",
    "    #상품 정보 div\n",
    "    metadata = browser.find_elements_by_css_selector('.basicList_item__2XT81')\n",
    "#     print(metadata)\n",
    "    \n",
    "\n",
    "    for metadatas in metadata:\n",
    "        try:\n",
    "            name = metadatas.find_element_by_css_selector('.basicList_title__3P9Q7').text\n",
    "            # print(name)\n",
    "            cate = metadatas.find_element_by_css_selector('.basicList_depth__2QIie').text\n",
    "    #         cate2 = cate.find('아동')\n",
    "    #         if cate2 == '아동':\n",
    "    #             pass\n",
    "    #         print('cate:',cate)\n",
    "    #         print('cate[0]:',cate[0])\n",
    "            products.append(cate[2:])\n",
    "            category.append(j)\n",
    "#             items.append(cate[8:])\n",
    "            items.append(plusUrl)\n",
    "            link = metadatas.find_element_by_css_selector('.basicList_title__3P9Q7 > a').get_attribute('href')\n",
    "#             link = metadatas.find_element_by_css_selector('.basicList_mall_title__3MWFY > a').get_attribute('href')\n",
    "            links.append(link)\n",
    "#             print(link)\n",
    "        \n",
    "            images = metadatas.find_element_by_css_selector('.thumbnail_thumb__3Agq6  > img').get_attribute('src')[:-10]\n",
    "            image_url.append(images)\n",
    "            detail = metadatas.find_element_by_css_selector('.basicList_desc__2-tko').text\n",
    "#             detail_sub = detail.find_elements_by_css_selector('.basicList_detail__27Krk').text\n",
    "\n",
    "\n",
    "            #네이버 기장 관련 데이터 있을 시 가져옴\n",
    "            detail1 = detail.find('총기장')\n",
    "#             if j =='드레스':\n",
    "            if detail1 == -1:\n",
    "                length.append('상세정보확인')\n",
    "            else:\n",
    "                length.append('상세정보확인')\n",
    "\n",
    "#             elif detail1 == 21:\n",
    "#                 length.append(detail[27:28])\n",
    "\n",
    "#             elif detail1 ==22:\n",
    "#                 length.append(detail[28:29])\n",
    "\n",
    "#             elif detail1 ==26:\n",
    "#                 length.append(detail[32:33])\n",
    "\n",
    "#             elif detail1 ==30:\n",
    "#                 length.append(detail[36:37])\n",
    "\n",
    "#             elif detail1 ==31:\n",
    "#                 length.append(detail[37:38])\n",
    "\n",
    "#             elif detail1 ==33:\n",
    "#                 length.append(detail[39:40])\n",
    "\n",
    "#             elif detail == 35:\n",
    "#                 length.append(detail[41:42])\n",
    "                    \n",
    "                    \n",
    "            detail2 = detail.find('소매기장')\n",
    "#             print(detail2)\n",
    "            if detail2 == -1:\n",
    "                sleeve_length.append('상세정보확인')\n",
    "            else:\n",
    "                sleeve_length.append('상세정보확인')\n",
    "            \n",
    "#             elif detail2 == 9:\n",
    "#                 sleeve_length.append(detail2[13:16])\n",
    "                \n",
    "#             elif detail2 == 15:\n",
    "#                 sleeve_length.append(detail2[19:25])\n",
    "                \n",
    "#             elif detail2 == 25:\n",
    "#                 sleeve_length.append(detail2[31:37])\n",
    "                \n",
    "#             elif detail2 == 26:\n",
    "#                 sleeve_length.append(detail2[32:38])\n",
    "                \n",
    "#             elif detail2 == 29:\n",
    "#                 sleeve_length.append(detail2[35:41])\n",
    "                \n",
    "#             elif detail2 == 30:\n",
    "#                 sleeve_length.append(detail2[36:42])\n",
    "                \n",
    "#             elif detail2 == 31:\n",
    "#                 sleeve_length.append(detail2[37:43])\n",
    "                \n",
    "#             elif detail2 == 32:\n",
    "#                 sleeve_length.append(detail2[38:44])\n",
    "                \n",
    "#             elif detail2 == 33:\n",
    "#                 sleeve_length.append(detail2[39:45])\n",
    "                \n",
    "#             elif detial2 == 35:\n",
    "#                 sleeve_length.append(detail2[41:47])\n",
    "                \n",
    "#             elif detail2 == 38:\n",
    "#                 sleeve_length.append(detail2[44:50])\n",
    "                \n",
    "#             elif detail2 == 41:\n",
    "#                 sleeve_length.append(detail2[47:53])\n",
    "                \n",
    "#             elif detail2 == 43:\n",
    "#                 sleeve_length.append(detail2[49:55])\n",
    "                \n",
    "#             elif detail2 == 44:\n",
    "#                 sleeve_length.append(detail2[50:56])\n",
    "                \n",
    "#             elif detail2 == 54:\n",
    "#                 sleeve_length.append(detail2[60:66])\n",
    "                \n",
    "#             elif detail2 == 63:                    \n",
    "#                 sleeve_length.append(detail2[69:75])\n",
    "            \n",
    "                   \n",
    "#             print(detail[27:28])\n",
    "        except:\n",
    "            pass\n",
    "#     print(length)\n",
    "#     print(images)\n",
    "#     print(images)\n",
    "#     print(links)\n",
    "#     print(images)\n",
    "#     print(type(link[0]))\n",
    "#     print('cate:',cate[2:4])\n",
    "#     print('items:',cate[8:])\n",
    "#     print('category',category)\n",
    "\n",
    "\n",
    "    img_folder = './images/naver/'+str(category[0])+'/'+ plusUrl\n",
    "    if not os.path.isdir(img_folder): # 없으면 새로 생성하는 조건문\n",
    "        os.makedirs(img_folder)\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for imgs in image_url:\n",
    "        i += 1\n",
    "        filename = urlretrieve(imgs, f'./images/naver/{str(category[0])}/{plusUrl}/' + plusUrl + '{0}.jpg'.format(i))\n",
    "#         print(filename)\n",
    "\n",
    "        try:\n",
    "            image = cv.imread(f'images/naver/{str(category[0])}/{plusUrl}/'+ plusUrl + '{0}.jpg'.format(i))\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "            image = cv.resize(image, (500, 300), interpolation=cv.INTER_AREA)\n",
    "            clt = KMeans(n_clusters=3)\n",
    "            clt.fit(image.reshape(-1, 3))\n",
    "            clt_1 = clt.fit(image.reshape(-1, 3))\n",
    "            palette_val, pal_dict, pal_rgb = palette_perc(clt_1)\n",
    "            dict_list = list(pal_dict.values())\n",
    "            pal_rgb_list = pal_rgb.tolist()\n",
    "            ind_list = [dict_list.index(x) for x in\n",
    "                        sorted(dict_list, reverse=True)[:2]]  # 불러온 사진에서 가장 많이 등장하는 두개의 색을 가져옵니다\n",
    "            img_rgb = pal_rgb_list[ind_list[-1]]  # 주로 가장 많이 등장하는 색이 배경색이고 두번째가 제품 색상이기에 구번째 rgb값을 구합니다\n",
    "            \n",
    "        except:\n",
    "            img_rgb = []\n",
    "        rgb.append(img_rgb)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    next_btn = browser.find_element_by_class_name('pagination_next__1ITTf')\n",
    "    \n",
    "    next_btn.click()\n",
    "\n",
    "    page += 1\n",
    "\n",
    "    if page > 10:\n",
    "        break\n",
    "\n",
    "        \n",
    "\n",
    "imagefile=[]\n",
    "\n",
    "\n",
    "#이미지 경로\n",
    "for filename in glob.iglob('./images/naver/'+str(category[0])+'/'+ plusUrl+'/'+'*.jpg', recursive=True):\n",
    "    imagefile.append(filename)\n",
    "    imagefile = natsort.natsorted(imagefile)\n",
    "\n",
    "# print(imagefile)\n",
    "\n",
    "        \n",
    "print('product:',len(products))\n",
    "print('categoryL',len(category))\n",
    "print('item:',len(items))\n",
    "# length\n",
    "# color\n",
    "print('rgb:',len(rgb))\n",
    "print('links',len(links))\n",
    "print('image_url',len(image_url))\n",
    "print('imagefile',len(imagefile))\n",
    "# price=[]\n",
    "\n",
    "# #csv 저장                                     \n",
    "r = zip(products,category,items,length,rgb,links,sleeve_length,imagefile)\n",
    "header = ['상품 분류','카테고리','아이템','기장','세부 색상','제품 링크','소매 기장','이미지 경로']\n",
    "with open(f'./images/naver/{str(category[0])}/{plusUrl}.csv', 'w+', newline ='',encoding='UTF-8') as file:\n",
    "    w = csv.writer(file)\n",
    "    dw = csv.DictWriter(file,delimiter=',',fieldnames=header)\n",
    "    dw.writeheader()\n",
    "    for row in r:\n",
    "        w.writerow(row)\n",
    "\n",
    "print('완료')\n",
    "\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c24605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db8d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f815572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763dad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf37b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
